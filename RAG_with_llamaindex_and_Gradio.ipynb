{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Install libraries and download data"],"metadata":{"id":"3tNqbTPJyOCj"}},{"cell_type":"code","source":["!pip install -q llama-index llama-index-llms-openai gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrS6JiURryKh","outputId":"54cac416-96e6-4ad1-db65-a1efb1550db3","executionInfo":{"status":"ok","timestamp":1716989653385,"user_tz":-180,"elapsed":43603,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!mkdir -p 'data/'\n","!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham_essay.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xb682efNryM3","outputId":"d3525ab7-aa45-44e0-d8e1-aa58fa0093c2","executionInfo":{"status":"ok","timestamp":1716989653833,"user_tz":-180,"elapsed":452,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-05-29 13:34:13--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75042 (73K) [text/plain]\n","Saving to: ‘data/paul_graham_essay.txt’\n","\n","data/paul_graham_es 100%[===================>]  73.28K  --.-KB/s    in 0.02s   \n","\n","2024-05-29 13:34:13 (3.20 MB/s) - ‘data/paul_graham_essay.txt’ saved [75042/75042]\n","\n"]}]},{"cell_type":"code","source":["import os\n","import gradio as gr\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","from llama_index.llms.openai import OpenAI"],"metadata":{"id":"-AgFHztgryPN","executionInfo":{"status":"ok","timestamp":1716989734248,"user_tz":-180,"elapsed":6960,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# only for Google Colab; please comment Kaggle part in this case\n","from google.colab import userdata\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","\n","# only for Kaggle; please comment Google Colab part in this case\n","#from kaggle_secrets import UserSecretsClient\n","#user_secrets = UserSecretsClient()\n","#os.environ[\"OPENAI_API_KEY\"] = user_secrets.get_secret(\"OPENAI_API_KEY\")"],"metadata":{"id":"RIE6RpRyjoxS","executionInfo":{"status":"ok","timestamp":1716989737477,"user_tz":-180,"elapsed":1319,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Chatbot with internal knowledge\n","\n","For each chat interaction:\n","- first generate a standalone question from conversation context and last message, then\n","- query the query engine with the condensed question for a response.\n","\n","\n"],"metadata":{"id":"uOxXE5mrwq0N"}},{"cell_type":"code","source":["llm = OpenAI(model=\"gpt-3.5-turbo\")\n","data = SimpleDirectoryReader(input_dir=\"./data/\").load_data()\n","index = VectorStoreIndex.from_documents(data)"],"metadata":{"id":"AIt8J1TyryRb","executionInfo":{"status":"ok","timestamp":1716989748195,"user_tz":-180,"elapsed":1902,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from llama_index.core.memory import ChatMemoryBuffer\n","\n","memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n","\n","context_prompt = \"\"\"\n","You are a chatbot, able to have normal interactions, as well as talk \\n\n","about an essay discussing Paul Grahams life \\n\n","Here are the relevant documents for the context: \\n\n","{context_str} \\n\n","Instruction: Use the previous chat history, or the context above, to interact and help the user.\n","\"\"\"\n","\n","chat_engine = index.as_chat_engine(\n","    chat_mode=\"condense_plus_context\",\n","    memory=memory,\n","    llm=llm,\n","    context_prompt=context_prompt,\n","    verbose=False,\n",")"],"metadata":{"id":"L8rRmr5cryTg","executionInfo":{"status":"ok","timestamp":1716989751421,"user_tz":-180,"elapsed":231,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Chat with your data"],"metadata":{"id":"Napku2kkspvq"}},{"cell_type":"code","source":["response = chat_engine.chat(\"What did Paul Graham do growing up\")\n","response.response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"71__0BVQryVv","outputId":"9051df14-677e-4bad-e790-b9d76409e31a","executionInfo":{"status":"ok","timestamp":1716989759145,"user_tz":-180,"elapsed":4686,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Paul Graham had a diverse range of experiences growing up. He was involved in painting and experimenting with new techniques in still life painting. Later on, he delved into the world of web applications, realizing their potential and founding companies like Viaweb and Aspra. Additionally, he explored the realm of programming languages, creating a new dialect of Lisp called Arc. Graham's journey also involved writing essays, working on spam filters, and engaging in various entrepreneurial ventures, ultimately leading to the creation of Y Combinator, an influential startup accelerator.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Ask follow-up question"],"metadata":{"id":"Y9ed4n09ssJp"}},{"cell_type":"code","source":["response_2 = chat_engine.chat(\"Can you tell me more?\")\n","response.response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"Kq6PudRrryYB","outputId":"5e78dbef-8f10-4544-edea-32ab10998d30","executionInfo":{"status":"ok","timestamp":1716989765893,"user_tz":-180,"elapsed":4993,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Paul Graham had a diverse range of experiences growing up. He was involved in painting and experimenting with new techniques in still life painting. Later on, he delved into the world of web applications, realizing their potential and founding companies like Viaweb and Aspra. Additionally, he explored the realm of programming languages, creating a new dialect of Lisp called Arc. Graham's journey also involved writing essays, working on spam filters, and engaging in various entrepreneurial ventures, ultimately leading to the creation of Y Combinator, an influential startup accelerator.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["### Use with Gradio"],"metadata":{"id":"8p-LZUCTvzfX"}},{"cell_type":"code","source":["def predict(message, history):\n","    response = chat_engine.chat(message)\n","    return response.response\n","\n","# Launch the Gradio interface with the prediction function\n","gr.ChatInterface(fn=predict, title=\"AI Chatbot with custom knowledge\", description=\"Answering questions about Paul Graham essay\").launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"INXV3LL0ryca","outputId":"b66c5f73-c808-40ee-e0b0-e99a5f9637f7","executionInfo":{"status":"ok","timestamp":1716989811213,"user_tz":-180,"elapsed":1501,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://6f59875242a0de2efe.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://6f59875242a0de2efe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Reset chat engine"],"metadata":{"id":"OxA1zH5rwOpi"}},{"cell_type":"code","source":["chat_engine.reset()"],"metadata":{"id":"Ep0sVGNwtoyP","executionInfo":{"status":"ok","timestamp":1716990084657,"user_tz":-180,"elapsed":2,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Chat Engine - ReAct Agent Mode"],"metadata":{"id":"arDPxk6ew9Lg"}},{"cell_type":"markdown","source":["ReAct is an agent based chat mode built on top of a query engine over your data.\n","\n","For each chat interaction, the agent enter a ReAct loop:\n","\n","- first decide whether to use the query engine tool and come up with appropriate input\n","- (optional) use the query engine tool and observe its output\n","- decide whether to repeat or give final response"],"metadata":{"id":"yHWnlAMuxGBL"}},{"cell_type":"code","source":["chat_engine = index.as_chat_engine(chat_mode=\"react\", llm=llm, verbose=True)"],"metadata":{"id":"ZrWY_zrTto2y","executionInfo":{"status":"ok","timestamp":1716990088760,"user_tz":-180,"elapsed":374,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["response = chat_engine.chat(\n","    \"Use the tool to answer what Graham do in the summer of 1995?\"\n",")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TCa_taoryek","outputId":"39ee25a8-36be-459a-f67d-25a620d6ee5e","executionInfo":{"status":"ok","timestamp":1716990095535,"user_tz":-180,"elapsed":4847,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Added user message to memory: Use the tool to answer what Graham do in the summer of 1995?\n","=== Calling Function ===\n","Calling function: query_engine_tool with args: {\"input\":\"What did Graham do in the summer of 1995?\"}\n","Got output: In the summer of 1995, Graham started working on a new kind of still life painting technique where he would paint one piece in the traditional way, then photograph it, print it on canvas, and use it as the underpainting for a second still life painting.\n","========================\n","\n","In the summer of 1995, Graham started working on a new kind of still life painting technique where he would paint one piece in the traditional way, then photograph it, print it on canvas, and use it as the underpainting for a second still life painting.\n"]}]},{"cell_type":"code","source":["response = chat_engine.chat(\"Is there any mention about 1995?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUCVOGgexqou","outputId":"c0797cdb-e92d-4f0f-eb13-657aa73a1c23","executionInfo":{"status":"ok","timestamp":1716990102534,"user_tz":-180,"elapsed":2876,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Added user message to memory: Is there any mention about 1995?\n","=== Calling Function ===\n","Calling function: query_engine_tool with args: {\"input\":\"Is there any mention about 1995?\"}\n","Got output: No, there is no mention of the year 1995 in the provided context information.\n","========================\n","\n","No, there is no mention of the year 1995 in the provided context information.\n"]}]},{"cell_type":"code","source":["response = chat_engine.chat(\"Who is Klaus Iohannis?\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGiGuaeJ0goE","outputId":"acd16212-c431-4311-837b-2702eacae7b6","executionInfo":{"status":"ok","timestamp":1716990197242,"user_tz":-180,"elapsed":3908,"user":{"displayName":"Cosmin Cojocaru","userId":"04159693239284349674"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Added user message to memory: Who is Klaus Iohannis?\n","=== Calling Function ===\n","Calling function: query_engine_tool with args: {\"input\":\"Who is Klaus Iohannis?\"}\n","Got output: I cannot provide an answer to that query as there is no mention or relevance to Klaus Iohannis in the provided context information.\n","========================\n","\n","I cannot provide an answer to that query as there is no mention or relevance to Klaus Iohannis in the provided context information.\n"]}]},{"cell_type":"markdown","source":["More examples on https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_condense_plus_context/"],"metadata":{"id":"yWPlkiiMzjTD"}}]}